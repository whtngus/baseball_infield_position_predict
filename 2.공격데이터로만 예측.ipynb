{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Supress default INFO logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load  and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수비와 타자를 이름으로 조합 시켜야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "defende_path = \"./data/수비/\"\n",
    "batter_path = \"./data/타자/\"\n",
    "file_list = ['2011.tsv','2012.tsv','2013.tsv','2014.tsv','2015.tsv','2016.tsv','2017.tsv','2018.tsv','2019.tsv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(file_list, defende_path,batter_path):\n",
    "    df = pd.DataFrame()\n",
    "    for data_path in file_list:\n",
    "        defender = pd.read_csv(defende_path + data_path,sep=\"\\t\")\n",
    "        batter = pd.read_csv(batter_path + data_path,sep=\"\\t\")\n",
    "        data = pd.merge(defender,batter,on=[\"선수명\",\"팀명\"])\n",
    "        df = pd.concat([df,data])\n",
    "    return df, list(defender.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_noise_column(data, columns):\n",
    "    noise_columns = [\"순위_x\",\"순위_y\",\"G_x\"] + columns\n",
    "    for column in noise_columns:\n",
    "        if column in data:\n",
    "            del data[column]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defender_coumns 제거를 위해  수비수 포지션을 받고  포지션은 제거 리스트에서 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, defender_coumns = data_load(file_list, defende_path, batter_path)\n",
    "del defender_coumns[defender_coumns.index(\"POS\")]\n",
    "del defender_coumns[defender_coumns.index(\"선수명\")]\n",
    "del defender_coumns[defender_coumns.index(\"팀명\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = del_noise_column(df,list(defender_coumns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 선수명은 나중에 값 확인을 위해 따로 빼기  + label 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"선수명\" in df:\n",
    "    df_name = df[\"선수명\"]\n",
    "    del df[\"선수명\"]\n",
    "\n",
    "label = None\n",
    "if \"POS\" in df:\n",
    "    label = df[\"POS\"]\n",
    "    del df[\"POS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 팀명 원핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"팀명\" in df:\n",
    "    one_hot_encoded = pd.get_dummies(df.팀명) \n",
    "    del df[\"팀명\"]\n",
    "    df = pd.concat([one_hot_encoded,df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_train_test(data,label):\n",
    "    '''\n",
    "    데이터를 트레이닝 테스트 데이터로 나눠서 반환\n",
    "    책에서는 train_test_split random_state=11의 파라미터를 주나 코드에서는 제거\n",
    "    :return:\n",
    "    '''\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data,label,\n",
    "                                                        test_size=0.2)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def find_model(model_name):\n",
    "    clt = None\n",
    "    if model_name == \"LogisticRegression\":\n",
    "        clt = LogisticRegression()\n",
    "    elif model_name == \"DecisionTreeClassifier\":\n",
    "        clt = DecisionTreeClassifier()\n",
    "    elif model_name == \"svm\":\n",
    "        clt = svm.SVC(gamma=0.001)\n",
    "    elif model_name == \"RandomForestClassifier\":\n",
    "        clt = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "    elif model_name == \"AdaBoostClassifier\":\n",
    "        clt = AdaBoostClassifier()\n",
    "    \n",
    "    return clt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sciket basic classification\n",
    "- 지원 모델 <br>\n",
    "```\n",
    "LogisticRegression \n",
    "DecisionTreeClassifier \n",
    "svm \n",
    "RandomForestClassifier\n",
    "AdaBoostClassifier \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sciket_basic_model_train(data, label,model, debug = False):\n",
    "    '''\n",
    "    데이터 트레이닝 및 예측 진행\n",
    "    :parameter model_save : 모델을 반환받기를 원할경우 True 입력\n",
    "    :return:\n",
    "    '''\n",
    "    print(\"================================================================\")\n",
    "    print(\"{} train\".format(model))\n",
    "    # 데이터 트레이닝\n",
    "    x_train, x_test, y_train, y_test = divide_train_test(data, label)\n",
    "    clt = find_model(model)\n",
    "    if clt == None:\n",
    "        print(\"***** 모델 없음 ****\")\n",
    "        return\n",
    "    clt.fit(x_train,y_train)\n",
    "    # 예측\n",
    "    pred = clt.predict(x_test)\n",
    "    print(\"모델 정확도 : {0:.4f}\".format(accuracy_score(y_test,pred)))\n",
    "    if debug:\n",
    "        print(list(y_test))\n",
    "        print(list(pred))\n",
    "        print(\" -- cross_val_score 5 -- \")\n",
    "        print(cross_val_score(clt, x_train,y_train, cv=5).mean())\n",
    "    print(\"================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_model_train(data, label,debug = False):\n",
    "    '''\n",
    "    데이터 트레이닝 및 예측 진행\n",
    "    :parameter model_save : 모델을 반환받기를 원할경우 True 입력\n",
    "    :return:\n",
    "    '''\n",
    "    print(\"Light gbm train\")\n",
    "    # 데이터 트레이닝\n",
    "    x_train, x_test, y_train, y_test = divide_train_test(data, label)\n",
    "    # 학습 모델\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'metric': {'multi_logloss'},\n",
    "        'num_leaves': 63,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 0,\n",
    "        'verbose': 0,\n",
    "        'num_class': 3\n",
    "    }\n",
    "    # create dataset for lightgbm\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_test = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "    lgb_model = lgb.train(params, lgb_train, num_boost_round=20,\n",
    "                          valid_sets=lgb_test, early_stopping_rounds=5)\n",
    "    # 예측\n",
    "    pred = lgb_model.predict(x_test)\n",
    "    pred = [pr.argmax() for pr in pred]\n",
    "    print(\"모델 정확도 : {0:.4f}\".format(accuracy_score(y_test, pred)))\n",
    "    print(list(y_test))\n",
    "    print(list(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "LogisticRegression train\n",
      "모델 정확도 : 0.4039\n",
      "================================================================\n",
      "================================================================\n",
      "svm train\n",
      "모델 정확도 : 0.2118\n",
      "================================================================\n",
      "================================================================\n",
      "DecisionTreeClassifier train\n",
      "모델 정확도 : 0.2000\n",
      "================================================================"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tool\\conda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "RandomForestClassifier train\n",
      "모델 정확도 : 0.2863\n",
      "================================================================\n",
      "================================================================\n",
      "AdaBoostClassifier train\n",
      "모델 정확도 : 0.3451\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "sciket_basic_model_train(df, label,\"LogisticRegression\")\n",
    "sciket_basic_model_train(df, label, \"svm\")\n",
    "sciket_basic_model_train(df, label, \"DecisionTreeClassifier\")\n",
    "sciket_basic_model_train(df, label, \"RandomForestClassifier\")\n",
    "sciket_basic_model_train(df, label, \"AdaBoostClassifier\")\n",
    "# print(lgbm_model_train(data, label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
